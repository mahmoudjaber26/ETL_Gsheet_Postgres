name: Nightly Google Sheets → BigQuery ETL

on:
  schedule:
    - cron: "15 01 * * *"   # 01:15 UTC (04:15 Asia/Amman)
  workflow_dispatch:

jobs:
  run-etl:
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install \
            pandas==2.2.* \
            pyarrow>=14 \
            google-cloud-bigquery>=3.20.0 \
            gspread oauth2client

      - name: Sanity: show files and secrets presence
        run: |
         ls -la
         python -c "import os,sys,pathlib; print('Python:', sys.version); print('Has config.json:', pathlib.Path('config.json').exists()); print('Has GOOGLE_CREDENTIALS_JSON secret in env? (should be False here):', bool(os.getenv('GOOGLE_CREDENTIALS_JSON')))"
      
      - name: Write Google credentials file from secret 
       run: |
         echo "$GOOGLE_CREDENTIALS_JSON" > powerbi-etl-creds.json
         python -c "import json; d=json.load(open('powerbi-etl-creds.json')); print('Service account email:', d.get('client_email'))"
      env:
        GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}

      - name: Run ETL (Sheets → BigQuery)
        env:
          ETL_CONFIG_FILE: config.json
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/powerbi-etl-creds.json
          # GCP_PROJECT: your-project-id   # set only if needed; otherwise comment out
          BQ_DATASET: etl_dataset
        run: |
          python ETLGS_Postgres_gsheet_Final.py   # <-- ensure this matches your script filename
